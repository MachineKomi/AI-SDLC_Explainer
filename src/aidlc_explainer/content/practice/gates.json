{
  "$schema": "gates-v1",
  "title": "Gatekeeper Practice",
  "description": "Practice reviewing AI-generated plans as a gate approver",
  "scenarios": [
    {
      "id": "g1",
      "phase": "Inception",
      "stage": "Requirements Analysis",
      "context": "You are reviewing an AI-generated requirements document for a user authentication feature. The AI claims the requirements are complete and ready for Construction.",
      "ai_plan": "## Authentication Requirements\n\n1. Users can log in with email and password\n2. Users can reset their password via email\n3. Session management with 24-hour timeout\n\n## Proposed Next Steps\n- Begin coding the login endpoint immediately\n- Add tests after the feature is complete\n- Security review at the end",
      "flaws": [
        "No acceptance criteria defined for each requirement",
        "Missing security NFRs (password hashing, rate limiting, MFA)",
        "Tests deferred until after coding (should be concurrent)",
        "Security review at end instead of upfront threat modeling",
        "No performance requirements (login latency, concurrent users)"
      ],
      "decisions": {
        "correct_action": "reject",
        "valid_reasons": [
          "Missing acceptance criteria",
          "No security requirements defined",
          "Tests should not be deferred",
          "Security review should happen earlier",
          "Missing performance requirements"
        ],
        "invalid_reasons": [
          "Requirements are too simple",
          "Should use OAuth instead of email/password",
          "24-hour session timeout is wrong"
        ]
      },
      "evidence_checklist": [
        "Acceptance criteria for each requirement",
        "Security NFRs: password hashing algorithm, rate limiting rules, MFA requirements",
        "Performance NFRs: max login latency, concurrent user capacity",
        "Test strategy document with coverage targets",
        "Threat model or security review approval"
      ],
      "sources": {
        "local": ["AI-SDLC_best-practice_method_principles.md#L86-99"],
        "upstream": ["https://github.com/aws-samples/sample-aidlc-workflows"]
      }
    },
    {
      "id": "g2",
      "phase": "Construction",
      "stage": "Unit Implementation",
      "context": "You are reviewing an AI-generated implementation plan for Unit 03 (API endpoints). The previous units have been completed and approved.",
      "ai_plan": "## Unit 03: API Endpoints Implementation Plan\n\n### Tasks\n- [x] Design document reviewed ✓\n- [x] Acceptance criteria confirmed ✓\n- [ ] Implement GET /users endpoint\n- [ ] Implement POST /users endpoint\n- [ ] Implement PUT /users/{id} endpoint\n- [ ] Implement DELETE /users/{id} endpoint\n- [ ] Add unit tests\n- [ ] Run integration tests\n- [ ] Update API documentation\n\n### Evidence\n- Design approved in construction/unit-03/design.md\n- All tests will be added after implementation",
      "flaws": [
        "Tests 'will be added after' - should be concurrent",
        "No mention of validation testing",
        "Missing error handling verification",
        "No performance/load testing mentioned"
      ],
      "decisions": {
        "correct_action": "reject",
        "valid_reasons": [
          "Tests should be concurrent, not after",
          "Missing validation testing plan",
          "No error handling verification",
          "Missing performance testing"
        ],
        "invalid_reasons": [
          "Too many endpoints",
          "Should use GraphQL instead",
          "Documentation update is unnecessary"
        ]
      },
      "evidence_checklist": [
        "Test plan showing concurrent test development",
        "Input validation test cases defined",
        "Error response test cases (400, 401, 404, 500)",
        "Performance baseline targets (requests/sec, latency)",
        "API documentation reviewed before implementation"
      ],
      "sources": {
        "local": ["AI-SDLC_best-practice_method_principles.md#L101-122"],
        "upstream": ["https://deepwiki.com/awslabs/aidlc-workflows/8-generated-artifacts"]
      }
    },
    {
      "id": "g3",
      "phase": "Construction",
      "stage": "Unit Completion",
      "context": "The AI has completed implementation of Unit 02 (Database Layer) and is requesting approval to mark the unit as Done. Review the completion evidence.",
      "ai_plan": "## Unit 02 Completion Report\n\n### Status: Ready for Approval\n\n### Completed Tasks\n- Created database schema (users, sessions, audit_log tables)\n- Implemented repository pattern for data access\n- Added connection pooling\n\n### Evidence\n- Code committed to feature branch\n- 'It works on my machine' - tested locally\n- Schema looks correct\n\n### Request\nPlease approve Unit 02 as complete so we can proceed to Unit 03.",
      "flaws": [
        "'Works on my machine' is not proof - needs automated tests",
        "No mention of test coverage or test results",
        "No acceptance criteria verification",
        "'Schema looks correct' is prose, not proof",
        "No migration scripts mentioned",
        "No review evidence"
      ],
      "decisions": {
        "correct_action": "reject",
        "valid_reasons": [
          "No automated test evidence",
          "No acceptance criteria verification",
          "No test coverage report",
          "Missing migration scripts",
          "'Looks correct' is not proof"
        ],
        "invalid_reasons": [
          "Should use NoSQL instead",
          "Connection pooling is premature optimization",
          "Repository pattern adds complexity"
        ]
      },
      "evidence_checklist": [
        "Automated test suite passing (CI green)",
        "Test coverage report meeting target threshold",
        "Each acceptance criterion verified with specific test",
        "Migration scripts tested (up and down)",
        "Code review approval documented",
        "Performance baseline established"
      ],
      "sources": {
        "local": ["AI-SDLC_best-practice_method_principles.md#L52-54", "AI-SDLC_best-practice_method_principles.md#L122"],
        "upstream": ["https://aws.amazon.com/blogs/devops/ai-driven-development-life-cycle/"]
      }
    },
    {
      "id": "g4",
      "phase": "Inception",
      "stage": "Unit Decomposition",
      "context": "You are reviewing an AI-proposed unit decomposition for a new feature. The AI has broken down the work into units and is requesting approval to proceed to Construction.",
      "ai_plan": "## Feature: Dashboard Analytics\n\n### Proposed Units\n\n**Unit 1: Everything**\n- Build complete analytics dashboard\n- Backend API, frontend UI, database schema\n- All charts and visualizations\n- User preferences storage\n- Export functionality\n- Real-time updates\n\n### Dependencies\n- None (self-contained)\n\n### Timeline\n- Estimated: 2 weeks\n\n### Request\nApprove this unit breakdown to begin Construction.",
      "flaws": [
        "Single monolithic unit - violates 'small, coherent units' principle",
        "No acceptance criteria per unit",
        "No dependency analysis between sub-components",
        "Mixed concerns (backend, frontend, database in one unit)",
        "No gate checkpoints within the large scope"
      ],
      "decisions": {
        "correct_action": "reject",
        "valid_reasons": [
          "Unit is too large - should be decomposed",
          "Missing acceptance criteria",
          "Mixed concerns (backend/frontend/database)",
          "No intermediate checkpoints",
          "No clear dependencies mapped"
        ],
        "invalid_reasons": [
          "2 weeks is too long",
          "Real-time updates are unnecessary",
          "Should use a different charting library"
        ]
      },
      "evidence_checklist": [
        "3-5 smaller units with single responsibility each",
        "Clear acceptance criteria for each unit",
        "Dependency graph showing unit relationships",
        "Estimated complexity/size for each unit",
        "Gate criteria defined for each unit completion",
        "Risk assessment for each unit"
      ],
      "sources": {
        "local": ["AI-SDLC_best-practice_method_principles.md#L40-43", "AI-SDLC_best-practice_method_principles.md#L97"],
        "upstream": ["https://aws.amazon.com/blogs/devops/building-with-ai-driven-development-life-cycle-ai-dlc-using-amazon-q-developer/"]
      }
    },
    {
      "id": "g5",
      "phase": "Construction",
      "stage": "Build and Test",
      "context": "You are reviewing a validation report for Unit 04. Most tests pass but there are some failures. The team is asking if they can proceed to the next unit.",
      "ai_plan": "## Unit 04 Validation Report\n\n### Test Results\n- Unit tests: 47/50 passed (94%)\n- Integration tests: 12/15 passed (80%)\n- Linting: Clean\n- Security scan: No critical issues\n\n### Failed Tests\n- test_edge_case_empty_input - FAILED (timeout)\n- test_concurrent_access - FAILED (race condition)\n- test_large_payload - FAILED (memory error)\n- test_payment_validation - FAILED (incorrect amount)\n- test_rollback_scenario - FAILED (data inconsistency)\n\n### Request\nCan we proceed? The failures are edge cases and we can fix them later.",
      "flaws": [
        "5 failed tests are not 'edge cases' - they indicate real bugs",
        "Concurrent access failure is a serious race condition",
        "Payment validation failure could cause financial issues",
        "Data inconsistency in rollback is a critical bug",
        "'Fix later' violates proof over prose"
      ],
      "decisions": {
        "correct_action": "reject",
        "valid_reasons": [
          "Failed tests indicate real bugs",
          "Race condition needs fixing before proceed",
          "Payment validation failure is critical",
          "Cannot defer bugs to later",
          "Data inconsistency is serious"
        ],
        "invalid_reasons": [
          "94% pass rate is good enough",
          "Edge cases can be ignored",
          "We can hotfix later",
          "Integration tests don't matter"
        ]
      },
      "evidence_checklist": [
        "All unit tests passing (100%)",
        "All integration tests passing (100%)",
        "Race condition root cause identified and fixed",
        "Payment validation logic reviewed and corrected",
        "Rollback scenario working correctly",
        "Re-run full test suite after fixes"
      ],
      "sources": {
        "local": ["AI-SDLC_best-practice_method_principles.md#L52-54"],
        "upstream": ["https://deepwiki.com/awslabs/aidlc-workflows/8-generated-artifacts"]
      }
    },
    {
      "id": "g6",
      "phase": "Construction",
      "stage": "Security Review",
      "context": "The security team has flagged concerns but the deadline is tomorrow. The PM is pushing to proceed. Review the situation.",
      "ai_plan": "## Security Review Findings\n\n### Critical Issues (0)\nNone found.\n\n### High Issues (2)\n1. SQL injection possible in search endpoint\n2. API keys exposed in client-side code\n\n### Medium Issues (4)\n- Missing rate limiting\n- No input sanitization on file uploads\n- Session tokens don't expire\n- Debug mode enabled in production config\n\n### PM Note\n'We need to ship tomorrow for the quarterly demo. Can we document these and fix in the next sprint?'",
      "flaws": [
        "SQL injection is a critical vulnerability, not just 'high'",
        "API keys in client code is a security breach waiting to happen",
        "Cannot ship known security vulnerabilities",
        "'Fix in next sprint' violates safety constraints",
        "Demo deadline doesn't override security"
      ],
      "decisions": {
        "correct_action": "reject",
        "valid_reasons": [
          "SQL injection must be fixed before ship",
          "API keys must be removed from client",
          "Cannot ship known vulnerabilities",
          "Security > schedule",
          "Debug mode in prod is dangerous"
        ],
        "invalid_reasons": [
          "It's just for a demo",
          "We can hotfix after the demo",
          "No one will find the vulnerabilities",
          "The deadline is more important"
        ]
      },
      "evidence_checklist": [
        "SQL injection vulnerability fixed and verified",
        "API keys moved to secure backend storage",
        "Rate limiting implemented",
        "File upload sanitization added",
        "Session token expiration configured",
        "Debug mode disabled in production",
        "Penetration test passed"
      ],
      "sources": {
        "local": ["AI-SDLC_best-practice_method_principles.md#L64-66"],
        "upstream": ["https://aws.amazon.com/blogs/devops/ai-driven-development-life-cycle/"]
      }
    },
    {
      "id": "g7",
      "phase": "Inception",
      "stage": "Requirements Analysis",
      "context": "Review this requirements document. The AI has done thorough work and the stakeholders are satisfied.",
      "ai_plan": "## Payment Processing Requirements\n\n### Functional Requirements\n\n**FR-01: Process Credit Card Payments**\n- Acceptance Criteria:\n  - AC1: System accepts Visa, Mastercard, Amex\n  - AC2: Transactions complete in < 3 seconds\n  - AC3: Failed transactions show clear error message\n  - AC4: Successful transactions generate receipt\n\n**FR-02: Handle Refunds**\n- Acceptance Criteria:\n  - AC1: Full refunds processed within 5 business days\n  - AC2: Partial refunds supported\n  - AC3: Refund notification sent to customer\n\n### Non-Functional Requirements\n- PCI-DSS compliance required\n- 99.9% uptime SLO\n- All transactions encrypted in transit and at rest\n- Audit log for all financial operations\n- Rate limiting: 100 transactions/minute/merchant\n\n### Security Review\n- Threat model approved by security team\n- Penetration test scheduled for Construction phase\n\n### Evidence\n- Stakeholder sign-off obtained\n- Legal review complete\n- Compliance checklist verified",
      "flaws": [],
      "decisions": {
        "correct_action": "approve",
        "valid_reasons": [
          "Clear acceptance criteria defined",
          "Security NFRs specified",
          "Compliance requirements included",
          "Stakeholder approval obtained",
          "Threat model completed"
        ],
        "invalid_reasons": [
          "Should add more features",
          "3 second timeout is too slow",
          "Should support cryptocurrency"
        ]
      },
      "evidence_checklist": [
        "Acceptance criteria for each requirement ✓",
        "Security NFRs defined ✓",
        "Compliance requirements documented ✓",
        "Stakeholder sign-off ✓",
        "Threat model approved ✓"
      ],
      "sources": {
        "local": ["AI-SDLC_best-practice_method_principles.md#L86-99"],
        "upstream": ["https://github.com/aws-samples/sample-aidlc-workflows"]
      }
    },
    {
      "id": "g8",
      "phase": "Inception",
      "stage": "Workflow Planning",
      "context": "The AI has proposed a workflow plan but seems to be skipping some stages. Review whether the plan is appropriate.",
      "ai_plan": "## Workflow Plan: Add Dark Mode Feature\n\n### Request Type: Brownfield (existing app)\n### Risk Level: Low\n### Estimated Effort: Small\n\n### Proposed Stages\n1. ~~Workspace Detection~~ (skip - already know the codebase)\n2. ~~Reverse Engineering~~ (skip - we built it ourselves)\n3. Requirements Analysis (minimal - just dark mode toggle)\n4. ~~User Stories~~ (skip - single feature)\n5. ~~Application Design~~ (skip - CSS changes only)\n6. Workflow Planning (this document)\n7. Code Generation (CSS variables + toggle component)\n8. Build and Test (visual regression tests)\n\n### Rationale\nThis is a simple UI enhancement. Full ceremony would be wasteful.",
      "flaws": [
        "Skipping Reverse Engineering even for brownfield is risky",
        "No analysis of where dark mode affects the app",
        "CSS-only assumption may be wrong (images, charts, third-party components)",
        "'We built it ourselves' doesn't mean we remember everything",
        "Should check for accessibility implications (contrast ratios)"
      ],
      "decisions": {
        "correct_action": "reject",
        "valid_reasons": [
          "Brownfield needs reverse engineering",
          "Impact analysis missing",
          "Accessibility not considered",
          "Third-party components not analyzed",
          "Images/charts may need dark versions"
        ],
        "invalid_reasons": [
          "Too many stages skipped",
          "Dark mode is too simple",
          "Should be full ceremony"
        ]
      },
      "evidence_checklist": [
        "Impact analysis: which components affected",
        "Accessibility review: contrast ratios for dark theme",
        "Third-party component compatibility check",
        "Image/chart dark mode variants identified",
        "User preference persistence mechanism defined",
        "Visual regression test plan"
      ],
      "sources": {
        "local": ["AI-SDLC_best-practice_method_principles.md#L48-50", "AI-SDLC_best-practice_method_principles.md#L218-226"],
        "upstream": ["https://deepwiki.com/awslabs/aidlc-workflows/3.2-adaptive-intelligence"]
      }
    },
    {
      "id": "g9",
      "phase": "Operations",
      "stage": "Production Readiness",
      "context": "The team is requesting approval to deploy to production. Review the production readiness evidence.",
      "ai_plan": "## Production Readiness Review\n\n### Deployment\n- IaC templates created (Terraform)\n- CI/CD pipeline configured\n- Staging deployment successful\n\n### Observability\n- Logging: CloudWatch configured\n- Metrics: Basic CPU/memory dashboards\n- Tracing: Not implemented yet\n\n### Operations\n- Runbooks: 'We will write them after we see what breaks'\n- Alerts: CPU > 80% alert configured\n- On-call: Not set up yet\n\n### Rollback\n- Blue/green deployment configured\n- Rollback not tested\n\n### Request\nWe'd like to deploy Monday. Can we get production approval?",
      "flaws": [
        "Tracing not implemented - can't debug distributed issues",
        "Runbooks 'after we see what breaks' is reactive, not proactive",
        "Only one alert (CPU) - need error rates, latency, etc.",
        "No on-call rotation defined",
        "Rollback not tested is a major gap"
      ],
      "decisions": {
        "correct_action": "reject",
        "valid_reasons": [
          "Tracing required for debugging",
          "Runbooks must exist before deploy",
          "Need more alerts (errors, latency)",
          "On-call must be defined",
          "Rollback must be tested"
        ],
        "invalid_reasons": [
          "Staging worked fine",
          "We can add tracing later",
          "Monday deadline is important"
        ]
      },
      "evidence_checklist": [
        "Distributed tracing implemented and verified",
        "Runbooks written for common incident types",
        "Alerts configured: error rate, latency p99, availability",
        "On-call rotation documented with escalation path",
        "Rollback tested successfully",
        "SLOs defined and dashboards created"
      ],
      "sources": {
        "local": ["AI-SDLC_best-practice_method_principles.md#L124-138"],
        "upstream": ["https://deepwiki.com/awslabs/aidlc-workflows/4-workflow-phases"]
      }
    },
    {
      "id": "g10",
      "phase": "Construction",
      "stage": "Unit Implementation",
      "context": "Halfway through Construction, the PM asks to add a new feature to the current unit. Review the scope change request.",
      "ai_plan": "## Scope Change Request\n\n### Original Scope (Unit 05: User Profile)\n- View profile\n- Edit profile\n- Upload avatar\n\n### Requested Addition\n'While you're in there, can you also add:\n- Social media link integration\n- Profile sharing via QR code\n- Activity feed on profile\n- Follower/following system'\n\n### PM Justification\n'These are related to the profile and it would be more efficient to do them together. The AI says it can handle it.'\n\n### Current Status\n- View profile: Complete\n- Edit profile: In progress\n- Upload avatar: Not started",
      "flaws": [
        "This is scope creep - 4 new features added mid-unit",
        "Social features are separate units (follower system is complex)",
        "Original unit not complete - shouldn't expand",
        "'More efficient' is false - creates larger, riskier change",
        "Activity feed and social features have their own acceptance criteria"
      ],
      "decisions": {
        "correct_action": "reject",
        "valid_reasons": [
          "Scope creep - complete original unit first",
          "Social features need separate units",
          "Follower system is complex enough for own unit",
          "Adding scope mid-unit increases risk",
          "Original acceptance criteria not met yet"
        ],
        "invalid_reasons": [
          "The features are related",
          "AI says it can handle it",
          "It would be more efficient"
        ]
      },
      "evidence_checklist": [
        "Original unit completed and approved first",
        "New features documented as separate units",
        "Acceptance criteria defined for each new feature",
        "Impact analysis on existing timeline",
        "Stakeholder approval for scope change",
        "Dependencies between new units mapped"
      ],
      "sources": {
        "local": ["AI-SDLC_best-practice_method_principles.md#L40-43"],
        "upstream": ["https://aws.amazon.com/blogs/devops/building-with-ai-driven-development-life-cycle-ai-dlc-using-amazon-q-developer/"]
      }
    }
  ]
}
